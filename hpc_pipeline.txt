########################################################################
# HPC RNA-seq Pipeline (Job-Array Script Generator + Alignment/Counts)
#
# Sections:
#  1) Trimming job scripts (Trimmomatic)
#  2) FastQC job scripts
#  3) Build HISAT2 reference (splice sites & exons)
#  4) Read alignment (HISAT2) job scripts
#  5) SAM -> BAM conversion job scripts (samtools sort)
#  6) Assemble/quantify with StringTie job scripts
#  7) Generate count matrices with prepDE.py
#
# Assumptions:
#  - You are on a module-enabled HPC cluster.
#  - Input FASTQs are paired-end and follow *_R1_001 / *_R2_001 naming.
#  - subheader-multi.sh is a cluster helper that writes submission headers.
#  - Output dirs like trimmed_reads/ and fastqc_output/ exist (create them).
#
# Tips:
#  - Inspect generated job scripts (*.sh) before submitting them.
#  - Replace module names/versions as needed for your cluster.
########################################################################

# =========================
# 1) Create Trimmomatic job scripts per sample
#    - Detects unique sample prefixes from *.fastq.gz
#    - Writes a Trimmomatic job script that loads the module and runs PE trimming
#    - Outputs paired/unpaired trimmed reads into trimmed_reads/
# =========================
#Trimming

samples=`ls *.fastq.gz | cut -d"_" -f1-4 | sort | uniq | tr "\n" " "`

for i in $samples; do
    subheader-multi.sh ${i}_trimmomatic 10G 24:00:00 bio-compute 16 > Trimmomatic_${i}.sh
    read1=`ls ${i}*_R1_001.* | tr "\n" "," | sed 's/,$/ /'`
    read2=`ls ${i}*_R2_001.* | tr "\n" "," | sed 's/,$/ /'`
    echo "module load apps/trimmomatic/0.39/noarch" >> Trimmomatic_${i}.sh
echo "java -jar trimmomatic_0.39/share/trimmomatic-0.39-2/trimmomatic.jar PE -threads 16 ${read1} ${read2} trimmed_reads/${i}_R1_paired.trimmed.fastq.gz trimmed_reads/${i}_R1_unpaired.trimmed.fastq.gz trimmed_reads/${i}_R2_paired.trimmed.fastq.gz trimmed_reads/${i}_R2_unpaired.trimmed.fastq.gz ILLUMINACLIP:trimmomatic_0.39/share/trimmomatic-0.39-2/adapters/TruSeq3-PE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:20 MINLEN:30" >> Trimmomatic_${i}.sh
done




# =========================
# 2) Create FastQC job scripts per sample
#    - Scans the same sample prefixes and generates a script running FastQC
#    - Outputs reports into fastqc_output/
# =========================
#FastQC
samples=`ls *.fastq.gz | cut -d" "_" -f1-4 | sort | uniq | tr "\n" " "`

for i in $samples; do
    subheader-multi.sh ${i}_fastqc 10G 24:00:00 bio-compute 16 > FastQC_${i}.sh
    read1=`ls ${i}*_R1_001.* | tr "\n" "," | sed 's/,$/ /'`
    read2=`ls ${i}*_R2_001.* | tr "\n" "," | sed 's/,$/ /'`
    echo "module load apps/fastqc/0.11.8/noarch" >> FastQC_${i}.sh
    echo "fastqc -o fastqc_output/ -f fastq ${read1} ${read2}" >> FastQC_${i}.sh
done


# =========================
# 3) Build HISAT2 reference & splice/exon annotation files
#    - Loads hisat2 module, derives splice sites/exons from GTF,
#      and builds the index named 'Bgla_Index' from Bgla_Geno.fna
# =========================
#Build HISAT reference annotation

module load hisat2/2.1.0

extract_splice_sites.py Bgla_Geno_Annos.gtf >Bgla_Geno.ss
extract_exons.py Bgla_Geno_Annos.gtf >Bgla_Geno.exon
hisat2-build  --ss Bgla_Geno.ss  --exon Bgla_Geno.exon Bgla_Geno.fna Bgla_Index


# =========================
# 4) Create HISAT2 alignment job scripts per sample
#    - Uses Bgla_Geno index; writes SAM output per sample
#    - NOTE: '/subheader-multi.sh' has a leading slash; confirm your path before running
# =========================
#Read Alignment

samples=`ls *.fastq.gz | cut -d"_" -f1-4 | sort | uniq | tr "\n" " "`

for i in $samples; do
    /subheader-multi.sh ${i}_hisat_align 40G 2-24:00:00 bio-compute 16 > HisatAlign_${i}.sh
    read1=`ls ${i}*_R1_* | tr "\n" "," | sed 's/,$/ /'`
    read2=`ls ${i}*_R2_* | tr "\n" "," | sed 's/,$/ /'`
    echo "module load hisat2/2.1.0" >> HisatAlign_${i}.sh
    echo "hisat2 -p 16 -q -S ${i}_aligned.sam -x Bgla_Geno -1 ${read1} ${read2}" >> HisatAlign_${i}.sh
done



# =========================
# 5) Create SAM->BAM conversion job scripts per sample
#    - Loads samtools and sorts each SAM into a BAM file
#    - Output naming pattern: ${sam_file}_Bgla_aligned.bam
# =========================
#sam2bam

# List all SAM files in the current directory
samples=`ls *.sam | cut -d"_" -f1-3 | sort | uniq | tr "\n" " "`

for i in $samples; do
    subheader-multi.sh "${i}_sam2bam" 10G 24:00:00 bio-compute 16 > "sam2bam_${i}.sh"
    sam_file=$(ls "${i}"*.sam)
    echo "module load apps/samtools/1.9/gcc-4.8.5" >> "sam2bam_${i}.sh"
    echo "samtools sort -@ 4 -o ${sam_file}_Bgla_aligned.bam ${sam_file}_aligned.sam" >> "sam2bam_${i}.sh"
done


# =========================
# 6) Create StringTie job scripts per BAM
#    - Loads stringtie + python2.7
#    - Runs StringTie with provided GTF to generate transcripts and abundance tables
# =========================
#Generate new reference annotations

samples=`ls *.bam | cut -d"_" -f1-3 | sort | uniq | tr "\n" " "`

for i in $samples; do
    subheader-multi.sh "${i}_new_ref_annos" 10G 24:00:00 bio-compute 16 > "new_ref_annos_${i}.sh"
    bam_file=$(ls "${i}"*.bam)
    echo "module load stringtie/1.3.6" >> "new_ref_annos_${i}.sh"
    echo "module load apps/python/2.7.8/gcc-4.8.5" >> "new_ref_annos_${i}.sh"
    echo "stringtie ${bam_file} -e -B -G blabrata_genome/Bglabrata_Geno_no_processing.gtf -o ${i}_transcripts.gtf -A ${bam_file}_counts" >> "new_ref_annos_${i}.sh"
done


# =========================
# 7) Generate gene/transcript count matrices with prepDE.py
#    - Expects samples.txt in current directory (see examples/samples.txt)
# =========================
#prepde

module load stringtie/1.3.6
module load apps/python/2.7.8/gcc-4.8.5

./prepDE.py -i ./samples.txt -g ./Gene_count_matrix.csv -t ./Transcript_count_matrix.csv -l 130
